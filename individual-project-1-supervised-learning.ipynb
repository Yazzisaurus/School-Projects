{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-17T03:12:55.059017Z","iopub.execute_input":"2023-04-17T03:12:55.059425Z","iopub.status.idle":"2023-04-17T03:12:55.076684Z","shell.execute_reply.started":"2023-04-17T03:12:55.059394Z","shell.execute_reply":"2023-04-17T03:12:55.075433Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"/kaggle/input/titanic-dataset-csv/CS379T-Week-1-IP.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Yasmine Dawud\n## April 16, 2023\n## CS379-2302A-01\n## Individual Project 1 - Supervised Machine Learning","metadata":{}},{"cell_type":"code","source":"#data analysis libraries \nimport numpy as np\nimport pandas as pd\n\n#visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-04-17T03:12:55.078842Z","iopub.execute_input":"2023-04-17T03:12:55.079222Z","iopub.status.idle":"2023-04-17T03:12:55.086805Z","shell.execute_reply.started":"2023-04-17T03:12:55.079187Z","shell.execute_reply":"2023-04-17T03:12:55.085925Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"#read CSV\ntitanic_df = pd.read_csv(\"/kaggle/input/titanic-dataset-csv/CS379T-Week-1-IP.csv\")\ntitanic_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T03:12:55.149715Z","iopub.execute_input":"2023-04-17T03:12:55.151116Z","iopub.status.idle":"2023-04-17T03:12:55.184266Z","shell.execute_reply.started":"2023-04-17T03:12:55.151064Z","shell.execute_reply":"2023-04-17T03:12:55.182875Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"   pclass  survived                                             name     sex  \\\n0     1.0       1.0                    Allen, Miss. Elisabeth Walton  female   \n1     1.0       1.0                   Allison, Master. Hudson Trevor    male   \n2     1.0       0.0                     Allison, Miss. Helen Loraine  female   \n3     1.0       0.0             Allison, Mr. Hudson Joshua Creighton    male   \n4     1.0       0.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n\n       age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n0  29.0000    0.0    0.0   24160  211.3375       B5        S    2    NaN   \n1   0.9167    1.0    2.0  113781  151.5500  C22 C26        S   11    NaN   \n2   2.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN    NaN   \n3  30.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN  135.0   \n4  25.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN    NaN   \n\n                         home.dest  \n0                     St Louis, MO  \n1  Montreal, PQ / Chesterville, ON  \n2  Montreal, PQ / Chesterville, ON  \n3  Montreal, PQ / Chesterville, ON  \n4  Montreal, PQ / Chesterville, ON  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pclass</th>\n      <th>survived</th>\n      <th>name</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>sibsp</th>\n      <th>parch</th>\n      <th>ticket</th>\n      <th>fare</th>\n      <th>cabin</th>\n      <th>embarked</th>\n      <th>boat</th>\n      <th>body</th>\n      <th>home.dest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>Allen, Miss. Elisabeth Walton</td>\n      <td>female</td>\n      <td>29.0000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>24160</td>\n      <td>211.3375</td>\n      <td>B5</td>\n      <td>S</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>St Louis, MO</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>Allison, Master. Hudson Trevor</td>\n      <td>male</td>\n      <td>0.9167</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>113781</td>\n      <td>151.5500</td>\n      <td>C22 C26</td>\n      <td>S</td>\n      <td>11</td>\n      <td>NaN</td>\n      <td>Montreal, PQ / Chesterville, ON</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>Allison, Miss. Helen Loraine</td>\n      <td>female</td>\n      <td>2.0000</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>113781</td>\n      <td>151.5500</td>\n      <td>C22 C26</td>\n      <td>S</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Montreal, PQ / Chesterville, ON</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>Allison, Mr. Hudson Joshua Creighton</td>\n      <td>male</td>\n      <td>30.0000</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>113781</td>\n      <td>151.5500</td>\n      <td>C22 C26</td>\n      <td>S</td>\n      <td>NaN</td>\n      <td>135.0</td>\n      <td>Montreal, PQ / Chesterville, ON</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n      <td>female</td>\n      <td>25.0000</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>113781</td>\n      <td>151.5500</td>\n      <td>C22 C26</td>\n      <td>S</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Montreal, PQ / Chesterville, ON</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Find the number duplicate record\nprint('titanic_df - Number of duplicate Record:', titanic_df.duplicated().sum())","metadata":{"execution":{"iopub.status.busy":"2023-04-17T03:12:55.186745Z","iopub.execute_input":"2023-04-17T03:12:55.187167Z","iopub.status.idle":"2023-04-17T03:12:55.201490Z","shell.execute_reply.started":"2023-04-17T03:12:55.187132Z","shell.execute_reply":"2023-04-17T03:12:55.199976Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"titanic_df - Number of duplicate Record: 0\n","output_type":"stream"}]},{"cell_type":"code","source":"#Find the number of null per each columns\nprint('Columns in titanic_df with null values:\\n')\nprint(titanic_df.isnull().sum())\nprint(\"-\"*30)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T03:12:55.202807Z","iopub.execute_input":"2023-04-17T03:12:55.203153Z","iopub.status.idle":"2023-04-17T03:12:55.213522Z","shell.execute_reply.started":"2023-04-17T03:12:55.203121Z","shell.execute_reply":"2023-04-17T03:12:55.211890Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Columns in titanic_df with null values:\n\npclass          1\nsurvived        1\nname            1\nsex             1\nage           264\nsibsp           1\nparch           1\nticket          1\nfare            2\ncabin        1015\nembarked        3\nboat          824\nbody         1189\nhome.dest     565\ndtype: int64\n------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"print(titanic_df.columns)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T03:12:55.216215Z","iopub.execute_input":"2023-04-17T03:12:55.216641Z","iopub.status.idle":"2023-04-17T03:12:55.230386Z","shell.execute_reply.started":"2023-04-17T03:12:55.216604Z","shell.execute_reply":"2023-04-17T03:12:55.228549Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Index(['pclass', 'survived', 'name', 'sex', 'age', 'sibsp', 'parch', 'ticket',\n       'fare', 'cabin', 'embarked', 'boat', 'body', 'home.dest'],\n      dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"titanic_df.sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T03:12:55.239100Z","iopub.execute_input":"2023-04-17T03:12:55.239786Z","iopub.status.idle":"2023-04-17T03:12:55.263382Z","shell.execute_reply.started":"2023-04-17T03:12:55.239746Z","shell.execute_reply":"2023-04-17T03:12:55.262206Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"      pclass  survived                                              name  \\\n846      3.0       0.0                                   Hampe, Mr. Leon   \n1301     3.0       0.0                              Youseff, Mr. Gerious   \n21       1.0       1.0  Beckwith, Mrs. Richard Leonard (Sallie Monypeny)   \n970      3.0       1.0                       Lindqvist, Mr. Eino William   \n256      1.0       1.0                            Salomon, Mr. Abraham L   \n\n         sex   age  sibsp  parch             ticket     fare cabin embarked  \\\n846     male  20.0    0.0    0.0             345769   9.5000   NaN        S   \n1301    male  45.5    0.0    0.0               2628   7.2250   NaN        C   \n21    female  47.0    1.0    1.0              11751  52.5542   D35        S   \n970     male  20.0    1.0    0.0  STON/O 2. 3101285   7.9250   NaN        S   \n256     male   NaN    0.0    0.0             111163  26.0000   NaN        S   \n\n     boat   body     home.dest  \n846   NaN    NaN           NaN  \n1301  NaN  312.0           NaN  \n21      5    NaN  New York, NY  \n970    15    NaN           NaN  \n256     1    NaN  New York, NY  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pclass</th>\n      <th>survived</th>\n      <th>name</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>sibsp</th>\n      <th>parch</th>\n      <th>ticket</th>\n      <th>fare</th>\n      <th>cabin</th>\n      <th>embarked</th>\n      <th>boat</th>\n      <th>body</th>\n      <th>home.dest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>846</th>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>Hampe, Mr. Leon</td>\n      <td>male</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>345769</td>\n      <td>9.5000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1301</th>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>Youseff, Mr. Gerious</td>\n      <td>male</td>\n      <td>45.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2628</td>\n      <td>7.2250</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>NaN</td>\n      <td>312.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>Beckwith, Mrs. Richard Leonard (Sallie Monypeny)</td>\n      <td>female</td>\n      <td>47.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>11751</td>\n      <td>52.5542</td>\n      <td>D35</td>\n      <td>S</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>New York, NY</td>\n    </tr>\n    <tr>\n      <th>970</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>Lindqvist, Mr. Eino William</td>\n      <td>male</td>\n      <td>20.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>STON/O 2. 3101285</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>15</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>256</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>Salomon, Mr. Abraham L</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>111163</td>\n      <td>26.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>New York, NY</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"titanic_df.describe(include = \"all\")","metadata":{"execution":{"iopub.status.busy":"2023-04-17T03:12:55.640643Z","iopub.execute_input":"2023-04-17T03:12:55.641773Z","iopub.status.idle":"2023-04-17T03:12:55.694924Z","shell.execute_reply.started":"2023-04-17T03:12:55.641718Z","shell.execute_reply":"2023-04-17T03:12:55.693617Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"             pclass     survived                  name   sex          age  \\\ncount   1309.000000  1309.000000                  1309  1309  1046.000000   \nunique          NaN          NaN                  1307     2          NaN   \ntop             NaN          NaN  Connolly, Miss. Kate  male          NaN   \nfreq            NaN          NaN                     2   843          NaN   \nmean       2.294882     0.381971                   NaN   NaN    29.881135   \nstd        0.837836     0.486055                   NaN   NaN    14.413500   \nmin        1.000000     0.000000                   NaN   NaN     0.166700   \n25%        2.000000     0.000000                   NaN   NaN    21.000000   \n50%        3.000000     0.000000                   NaN   NaN    28.000000   \n75%        3.000000     1.000000                   NaN   NaN    39.000000   \nmax        3.000000     1.000000                   NaN   NaN    80.000000   \n\n              sibsp        parch    ticket         fare        cabin embarked  \\\ncount   1309.000000  1309.000000      1309  1308.000000          295     1307   \nunique          NaN          NaN       929          NaN          186        3   \ntop             NaN          NaN  CA. 2343          NaN  C23 C25 C27        S   \nfreq            NaN          NaN        11          NaN            6      914   \nmean       0.498854     0.385027       NaN    33.295479          NaN      NaN   \nstd        1.041658     0.865560       NaN    51.758668          NaN      NaN   \nmin        0.000000     0.000000       NaN     0.000000          NaN      NaN   \n25%        0.000000     0.000000       NaN     7.895800          NaN      NaN   \n50%        0.000000     0.000000       NaN    14.454200          NaN      NaN   \n75%        1.000000     0.000000       NaN    31.275000          NaN      NaN   \nmax        8.000000     9.000000       NaN   512.329200          NaN      NaN   \n\n       boat        body     home.dest  \ncount   486  121.000000           745  \nunique   27         NaN           369  \ntop      13         NaN  New York, NY  \nfreq     39         NaN            64  \nmean    NaN  160.809917           NaN  \nstd     NaN   97.696922           NaN  \nmin     NaN    1.000000           NaN  \n25%     NaN   72.000000           NaN  \n50%     NaN  155.000000           NaN  \n75%     NaN  256.000000           NaN  \nmax     NaN  328.000000           NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pclass</th>\n      <th>survived</th>\n      <th>name</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>sibsp</th>\n      <th>parch</th>\n      <th>ticket</th>\n      <th>fare</th>\n      <th>cabin</th>\n      <th>embarked</th>\n      <th>boat</th>\n      <th>body</th>\n      <th>home.dest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1309.000000</td>\n      <td>1309.000000</td>\n      <td>1309</td>\n      <td>1309</td>\n      <td>1046.000000</td>\n      <td>1309.000000</td>\n      <td>1309.000000</td>\n      <td>1309</td>\n      <td>1308.000000</td>\n      <td>295</td>\n      <td>1307</td>\n      <td>486</td>\n      <td>121.000000</td>\n      <td>745</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1307</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>929</td>\n      <td>NaN</td>\n      <td>186</td>\n      <td>3</td>\n      <td>27</td>\n      <td>NaN</td>\n      <td>369</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Connolly, Miss. Kate</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>CA. 2343</td>\n      <td>NaN</td>\n      <td>C23 C25 C27</td>\n      <td>S</td>\n      <td>13</td>\n      <td>NaN</td>\n      <td>New York, NY</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>843</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11</td>\n      <td>NaN</td>\n      <td>6</td>\n      <td>914</td>\n      <td>39</td>\n      <td>NaN</td>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.294882</td>\n      <td>0.381971</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>29.881135</td>\n      <td>0.498854</td>\n      <td>0.385027</td>\n      <td>NaN</td>\n      <td>33.295479</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>160.809917</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.837836</td>\n      <td>0.486055</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14.413500</td>\n      <td>1.041658</td>\n      <td>0.865560</td>\n      <td>NaN</td>\n      <td>51.758668</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>97.696922</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.166700</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>7.895800</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>72.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>14.454200</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>155.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>39.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>31.275000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>256.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>80.000000</td>\n      <td>8.000000</td>\n      <td>9.000000</td>\n      <td>NaN</td>\n      <td>512.329200</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>328.000000</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(pd.isnull(titanic_df).sum())","metadata":{"execution":{"iopub.status.busy":"2023-04-17T03:12:55.698263Z","iopub.execute_input":"2023-04-17T03:12:55.698726Z","iopub.status.idle":"2023-04-17T03:12:55.707306Z","shell.execute_reply.started":"2023-04-17T03:12:55.698681Z","shell.execute_reply":"2023-04-17T03:12:55.705721Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"pclass          1\nsurvived        1\nname            1\nsex             1\nage           264\nsibsp           1\nparch           1\nticket          1\nfare            2\ncabin        1015\nembarked        3\nboat          824\nbody         1189\nhome.dest     565\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"#we'll start off by dropping the Cabin feature since not a lot more useful information can be extracted from it.\ntitanic_df = titanic_df.drop(['cabin'], axis = 1)\ntitanic_df = titanic_df.drop(['ticket'], axis = 1)\ntitanic_df = titanic_df.drop(['name'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T03:12:55.708605Z","iopub.execute_input":"2023-04-17T03:12:55.709191Z","iopub.status.idle":"2023-04-17T03:12:55.723368Z","shell.execute_reply.started":"2023-04-17T03:12:55.709134Z","shell.execute_reply":"2023-04-17T03:12:55.722079Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"#now we need to fill in the missing values in the Embarked feature\nprint(\"Number of people embarking in Southampton (S):\")\nsouthampton = titanic_df[titanic_df[\"embarked\"] == \"S\"].shape[0]\nprint(southampton)\n\nprint(\"Number of people embarking in Cherbourg (C):\")\ncherbourg = titanic_df[titanic_df[\"embarked\"] == \"C\"].shape[0]\nprint(cherbourg)\n\nprint(\"Number of people embarking in Queenstown (Q):\")\nqueenstown = titanic_df[titanic_df[\"embarked\"] == \"Q\"].shape[0]\nprint(queenstown)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T03:12:55.725170Z","iopub.execute_input":"2023-04-17T03:12:55.725516Z","iopub.status.idle":"2023-04-17T03:12:55.740950Z","shell.execute_reply.started":"2023-04-17T03:12:55.725484Z","shell.execute_reply":"2023-04-17T03:12:55.739462Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"Number of people embarking in Southampton (S):\n914\nNumber of people embarking in Cherbourg (C):\n270\nNumber of people embarking in Queenstown (Q):\n123\n","output_type":"stream"}]},{"cell_type":"code","source":"titanic_df = titanic_df.fillna({\"embarked\":\"S\"})","metadata":{"execution":{"iopub.status.busy":"2023-04-17T03:12:55.743938Z","iopub.execute_input":"2023-04-17T03:12:55.744299Z","iopub.status.idle":"2023-04-17T03:12:55.750992Z","shell.execute_reply.started":"2023-04-17T03:12:55.744265Z","shell.execute_reply":"2023-04-17T03:12:55.750021Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"#map each Embarked value to a numerical value\nembarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\ntitanic_df['embarked'] = titanic_df['embarked'].map(embarked_mapping)\n\ntitanic_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T03:12:55.752643Z","iopub.execute_input":"2023-04-17T03:12:55.753053Z","iopub.status.idle":"2023-04-17T03:12:55.780816Z","shell.execute_reply.started":"2023-04-17T03:12:55.753009Z","shell.execute_reply":"2023-04-17T03:12:55.779328Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"   pclass  survived     sex      age  sibsp  parch      fare  embarked boat  \\\n0     1.0       1.0  female  29.0000    0.0    0.0  211.3375         1    2   \n1     1.0       1.0    male   0.9167    1.0    2.0  151.5500         1   11   \n2     1.0       0.0  female   2.0000    1.0    2.0  151.5500         1  NaN   \n3     1.0       0.0    male  30.0000    1.0    2.0  151.5500         1  NaN   \n4     1.0       0.0  female  25.0000    1.0    2.0  151.5500         1  NaN   \n\n    body                        home.dest  \n0    NaN                     St Louis, MO  \n1    NaN  Montreal, PQ / Chesterville, ON  \n2    NaN  Montreal, PQ / Chesterville, ON  \n3  135.0  Montreal, PQ / Chesterville, ON  \n4    NaN  Montreal, PQ / Chesterville, ON  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pclass</th>\n      <th>survived</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>sibsp</th>\n      <th>parch</th>\n      <th>fare</th>\n      <th>embarked</th>\n      <th>boat</th>\n      <th>body</th>\n      <th>home.dest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>female</td>\n      <td>29.0000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>211.3375</td>\n      <td>1</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>St Louis, MO</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>male</td>\n      <td>0.9167</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>151.5500</td>\n      <td>1</td>\n      <td>11</td>\n      <td>NaN</td>\n      <td>Montreal, PQ / Chesterville, ON</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>female</td>\n      <td>2.0000</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>151.5500</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Montreal, PQ / Chesterville, ON</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>male</td>\n      <td>30.0000</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>151.5500</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>135.0</td>\n      <td>Montreal, PQ / Chesterville, ON</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>female</td>\n      <td>25.0000</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>151.5500</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Montreal, PQ / Chesterville, ON</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#map each Sex value to a numerical value\nsex_mapping = {\"male\": 0, \"female\": 1}\ntitanic_df['sex'] = titanic_df['sex'].map(sex_mapping)\n\ntitanic_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T03:22:12.285171Z","iopub.execute_input":"2023-04-17T03:22:12.285619Z","iopub.status.idle":"2023-04-17T03:22:12.310435Z","shell.execute_reply.started":"2023-04-17T03:22:12.285585Z","shell.execute_reply":"2023-04-17T03:22:12.308933Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"   pclass  survived  sex      age  sibsp  parch      fare  embarked boat  \\\n0     1.0       1.0  NaN  29.0000    0.0    0.0  211.3375         1    2   \n1     1.0       1.0  NaN   0.9167    1.0    2.0  151.5500         1   11   \n2     1.0       0.0  NaN   2.0000    1.0    2.0  151.5500         1  NaN   \n3     1.0       0.0  NaN  30.0000    1.0    2.0  151.5500         1  NaN   \n4     1.0       0.0  NaN  25.0000    1.0    2.0  151.5500         1  NaN   \n\n    body                        home.dest  \n0    NaN                     St Louis, MO  \n1    NaN  Montreal, PQ / Chesterville, ON  \n2    NaN  Montreal, PQ / Chesterville, ON  \n3  135.0  Montreal, PQ / Chesterville, ON  \n4    NaN  Montreal, PQ / Chesterville, ON  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pclass</th>\n      <th>survived</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>sibsp</th>\n      <th>parch</th>\n      <th>fare</th>\n      <th>embarked</th>\n      <th>boat</th>\n      <th>body</th>\n      <th>home.dest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>29.0000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>211.3375</td>\n      <td>1</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>St Louis, MO</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>0.9167</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>151.5500</td>\n      <td>1</td>\n      <td>11</td>\n      <td>NaN</td>\n      <td>Montreal, PQ / Chesterville, ON</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>2.0000</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>151.5500</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Montreal, PQ / Chesterville, ON</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>30.0000</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>151.5500</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>135.0</td>\n      <td>Montreal, PQ / Chesterville, ON</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>25.0000</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>151.5500</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Montreal, PQ / Chesterville, ON</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X_train = titanic_df.drop(\"survived\", axis=1)\nY_train = titanic_df[\"sex\"]\nX_test  = titanic_df.drop(\"age\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-17T03:37:16.914817Z","iopub.execute_input":"2023-04-17T03:37:16.915252Z","iopub.status.idle":"2023-04-17T03:37:16.926136Z","shell.execute_reply.started":"2023-04-17T03:37:16.915215Z","shell.execute_reply":"2023-04-17T03:37:16.924739Z"},"trusted":true},"execution_count":99,"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"((1310, 10), (1310,), (1310, 10))"},"metadata":{}}]},{"cell_type":"code","source":"#Using LogisticRegression\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(X_train, Y_train)\nY_pred = model.predict(X_test)\n\nfrom sklearn.metrics import accuracy_score\nlras=accuracy_score(Y_test,Y_pred)*100\nlras","metadata":{"execution":{"iopub.status.busy":"2023-04-17T03:37:19.341915Z","iopub.execute_input":"2023-04-17T03:37:19.342309Z","iopub.status.idle":"2023-04-17T03:37:19.376907Z","shell.execute_reply.started":"2023-04-17T03:37:19.342276Z","shell.execute_reply":"2023-04-17T03:37:19.374633Z"},"trusted":true},"execution_count":100,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/3856611561.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m             \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m             \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"liblinear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sag\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"saga\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m         )\n\u001b[1;32m   1516\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m     )\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 raise ValueError(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m     def __array_wrap__(\n","\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'D'"],"ename":"ValueError","evalue":"could not convert string to float: 'D'","output_type":"error"}]}]}